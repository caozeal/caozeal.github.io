---
title: LangChainå­¦ä¹ ç¬”è®°ï¼ˆä¸€ï¼‰
date: 2023-07-01 14:17:43
tags:
excerpt: LangChainæ˜¯ä¸€ä¸ªç”¨äºå¼€å‘ç”±è¯­è¨€æ¨¡å‹é©±åŠ¨çš„åº”ç”¨ç¨‹åºæ¡†æ¶ã€‚
---

# LangChainå­¦ä¹ ç¬”è®°ï¼ˆä¸€ï¼‰

> æ–‡ä¸­å¤§éƒ¨åˆ†éƒ½å¯ä»¥åœ¨[å®˜æ–¹æ–‡æ¡£](https://python.langchain.com/)ä¸­æ‰¾åˆ°ï¼Œç¤ºä¾‹ä¸ºè‡ªå·±çš„å®è·µï¼Œæœ‰æ¡ä»¶å¯ä»¥ç›´æ¥å‚è€ƒå®˜æ–¹æ–‡æ¡£ã€‚

## 1. ä»€ä¹ˆæ˜¯LangChain

> LangChain is a framework for developing applications powered by language models. We believe that the most powerful and differentiated applications will not only call out to a language model via an api, but will also:
> 1. Be data-aware: connect a language model to other sources of data
> 2. Be agentic: Allow a language model to interact with its environment

> LangChainæ˜¯ä¸€ä¸ªç”¨äºå¼€å‘ç”±è¯­è¨€æ¨¡å‹é©±åŠ¨çš„åº”ç”¨ç¨‹åºæ¡†æ¶ã€‚æˆ‘ä»¬ç›¸ä¿¡ï¼Œæœ€å¼ºå¤§å’Œæœ‰å·®å¼‚åŒ–çš„åº”ç”¨ç¨‹åºä¸ä»…ä¼šé€šè¿‡APIè°ƒç”¨è¯­è¨€æ¨¡å‹ï¼Œè¿˜ä¼šå…·å¤‡ä»¥ä¸‹ç‰¹ç‚¹ï¼š
> 1. æ•°æ®æ„ŸçŸ¥ï¼šå°†è¯­è¨€æ¨¡å‹è¿æ¥åˆ°å…¶ä»–æ•°æ®æºã€‚
> 2. æ™ºèƒ½ä»£ç†ï¼šå…è®¸è¯­è¨€æ¨¡å‹ä¸å…¶ç¯å¢ƒè¿›è¡Œäº¤äº’ã€‚

éšç€chatgptçš„ç«çˆ†ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ­£åœ¨æˆä¸ºä¸€ç§å…·æœ‰å˜é©æ€§çš„æŠ€æœ¯ï¼Œå›´ç»•å¤§è¯­è¨€æ¨¡å‹çš„è¾…åŠ©å¼€å‘æ¡†æ¶LangChainä¹Ÿé—®ä¸–äº†ï¼Œå®ƒä¸ä»…å¯ä»¥ä½¿æˆ‘ä»¬æ›´æ–¹ä¾¿çš„è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹çš„apiï¼Œä¹Ÿå¯ä»¥ä½¿å…¶ä¸å…¶ä»–çš„èµ„æºï¼ˆæ•°æ®æº/shell/apiï¼‰è¿›è¡Œäº¤äº’ï¼Œå……åˆ†å‘æŒ¥å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ã€‚

### æ¨¡å—
LangChainæœ‰å…­ä¸ªæ¨¡å—ï¼š
1. Model I/O(IOæ¨¡å‹)ï¼šæä¾›ä¸å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œäº¤äº’çš„æ¥å£
![Model_IO](../resources/langchain_iomodel.jpg)
2. Data Connection(æ•°æ®è¿æ¥)ï¼šæä¾›ç‰¹å®šäºåº”ç”¨æ•°æ®çš„æ¥å£
![Data_Connection](../resources/langchain_dataconnection.jpg)
3. Chainsï¼šé€šç”¨è§£é‡Šä¸ºå¯¹ç»„ä»¶çš„è°ƒç”¨åºåˆ—ï¼Œå¯ä»¥å°†å¤šä¸ªè°ƒç”¨é“¾æ¥èµ·æ¥
4. Memory(è®°å¿†æ¨¡å—)ï¼š ç”¨äºä¿ç•™ä¸€ä¸ªchainä¸­åº”ç”¨ç¨‹åºçš„çŠ¶æ€
5. Agents(ä»£ç†æ¨¡å—)ï¼šæä¾›å…¶ä»–å·¥å…·çš„ä»£ç†ï¼Œä½¿å¾—chainå¯ä»¥å†³å®šå¹¶ä½¿ç”¨æŸäº›å·¥å…·ï¼Œæ¯”å¦‚æ‰§è¡Œshellå‘½ä»¤ï¼Œè°ƒç”¨google apiè¿›è¡Œæœç´¢ç­‰
6. Callbacks(å›è°ƒæ¨¡å—)ï¼šç”¨äºæ—¥å¿—è®°å½•ã€ç›‘æ§ã€æµå¼ä¼ è¾“ç­‰

## 2. æ„å»ºåº”ç”¨

### 2.1 å®‰è£…
```bash
pip install langchain  #å®‰è£…langchain
pip intstall openai    #å®‰è£…openai
```

- è®¾ç½®`OPENAI_API_KEY`ç¯å¢ƒå˜é‡

### 2.2 é€šè¿‡å¤§è¯­è¨€æ¨¡å‹è·å–é¢„æµ‹
å¯¹å¤§è¯­è¨€æ¨¡å‹åŸºç¡€çš„è°ƒç”¨

```python
from langchain.llms import OpenAI

# temperature: 0.0-2.0, è¶Šå¤§è¶Šéšæœºï¼›modelï¼šé»˜è®¤ä½¿ç”¨text-davinci-003
llm = OpenAI(temperature=0.9, client="llms", model="text-davinci-003")

print(llm.predict("åˆ—ä¸¾ä¸‰ç§æ°´æœ"))
#ä¹Ÿå¯ä»¥å†™ä½œ
print(llm("åˆ—ä¸¾ä¸‰ç§æ°´æœ"))
```
è¾“å‡ºï¼š
```bash
è‹¹æœã€æ¢¨ã€æ©˜å­
```

### 2.3 å¯¹å¯¹è¯æ¨¡å‹çš„è°ƒç”¨
èŠå¤©æ¨¡å‹æ˜¯å¤§è¯­è¨€æ¨¡å‹çš„å˜ä½“ã€‚ä¸å¤§è¯­è¨€æ¨¡å‹ä¸åŒçš„æ˜¯ï¼Œå¤§è¯­è¨€æ¨¡å‹ä»¥æ–‡æœ¬è¿›è¡Œäº¤äº’ï¼ŒèŠå¤©æ¨¡å‹å¯ä»¥ä½¿ç”¨`AIMessage`,`HumanMessage`,`SystemMessage`è¿›è¡Œäº¤äº’ï¼Œåˆ†åˆ«å¯¹åº”openaiä¸­çš„`system`,`user`,`assistant`è§’è‰²ã€‚

```python
from langchain.cache import Base
from langchain.chat_models import ChatOpenAI
from langchain.schema import (HumanMessage, SystemMessage)

# model é»˜è®¤ä½¿ç”¨gpt-3.5-turbo
chat = ChatOpenAI(temperature=0.9, client="chat")
result = chat.predict_messages(
    [
        SystemMessage(content="ä»¥ä¸‹æ˜¯AIåŠ©æ‰‹ä¸äººç±»ä¹‹é—´çš„å‹å¥½å¯¹è¯ã€‚"),
        HumanMessage(content="æŠŠè¿™å¥è¯ç¿»è¯‘ä¸ºè‹±è¯­ï¼šæˆ‘çˆ±ä½ ã€‚"),
    ])

print(result)
```
è¾“å‡ºï¼š
```bash
content='The translation of this sentence to English is: "I love you."' additional_kwargs={} example=False
```

å½“ç„¶ä¹Ÿå¯ä»¥ç›´æ¥ä»¥æ–‡æœ¬è¿›è¡Œäº¤äº’
```python
print(chat.predict("æŠŠè¿™å¥è¯ç¿»è¯‘ä¸ºè‹±è¯­ï¼šæˆ‘çˆ±ä½ ã€‚"))
```
è¾“å‡ºï¼š
```bash
I love you.
```

### 2.4 Prompt templates(æç¤ºæ¨¡æ¿)
ä¾¿äºæ ¹æ®ä¸åŒçš„ä¸Šä¸‹æ–‡æ¥ç”Ÿæˆä¸åŒçš„promptï¼Œåº”ç”¨ç¨‹åºè°ƒç”¨èµ·æ¥æ›´çµæ´»

```python
from langchain.prompts import (ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate)

system_template = "ä½ æ˜¯ä¸€ä¸ªç¿»è¯‘åŠ©æ‰‹ï¼Œå¸®åŠ©äººä»¬æŠŠ{æºè¯­è¨€}ç¿»è¯‘ä¸º{ç›®æ ‡è¯­è¨€}"
system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)
human_template = "{æ–‡æœ¬}"
human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)

chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])

format = chat_prompt.format_messages(æºè¯­è¨€="æ±‰è¯­", ç›®æ ‡è¯­è¨€="è‹±è¯­", æ–‡æœ¬="æˆ‘çˆ±ä½ ")

print(format)
```
è¾“å‡ºï¼š
```bash
[SystemMessage(content='ä½ æ˜¯ä¸€ä¸ªç¿»è¯‘åŠ©æ‰‹ï¼Œå¸®åŠ©äººä»¬æŠŠæ±‰è¯­ç¿»è¯‘ä¸ºè‹±è¯­', additional_kwargs={}), HumanMessage(content='æˆ‘çˆ±ä½ ', additional_kwargs={}, example=False)]
```

ç”¨äºåç»­è°ƒç”¨
```python
chat = ChatOpenAI(temperature=0.9, client="chat")
print(chat.predict_messages(format))
```
è¾“å‡ºï¼š
```
content='I love you.' additional_kwargs={} example=False
```

### 2.5 Chains
æˆ‘ä»¬ä¹Ÿå¯ä»¥ä½¿ç”¨chainæ¥ç»„è£…modelå’Œprompt
```python
# åœ¨2.4çš„åŸºç¡€ä¸Šæ·»åŠ 
from langchain import LLMChain

chain = LLMChain(llm=chat, prompt=chat_prompt)
result = chain.run(æºè¯­è¨€="æ±‰è¯­", ç›®æ ‡è¯­è¨€="è‹±è¯­", æ–‡æœ¬="æˆ‘çˆ±ä½ ")

print(result)
```
è¾“å‡ºï¼š
```bash
I love you.
```

### 2.6 Agents
ä½¿ç”¨ä»£ç†æ¥è°ƒç”¨å·¥å…·ä»¥å®Œæˆæ›´å¤æ‚çš„ä»»åŠ¡ã€‚ä½¿ç”¨ä»£ç†åˆ†ä¸ºä¸‰æ­¥ï¼š
1. é€‰æ‹©è¯­è¨€æ¨¡å‹ï¼šLLM/Chat Model
2. é€‰æ‹©å·¥å…·ï¼šä¾‹å¦‚ï¼ŒGoogle Searchï¼ŒShell, ChatGPT Pluginsç­‰
3. æ„å»ºä»£ç†

æ¯”å¦‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨SerpAPIé€šè¿‡è°·æ­Œæœç´¢æŸäº›ä¸œè¥¿å¹¶è¿›è¡Œç®€å•çš„æ•°å­¦è®¡ç®—ï¼š
- å®‰è£…åŒ…ï¼š`pip install google-search-results`
- è®¾ç½®ç¯å¢ƒå˜é‡ï¼š`SERPAPI_API_KEY`

```python
from langchain.agents import AgentType, initialize_agent, load_tools
from langchain.llms import OpenAI

llm = OpenAI(temperature=0, client="agent", model="text-davinci-003")

# serpapi: å¯ä»¥ç”¨æ¥è°ƒç”¨googleçš„apiï¼Œllm-mathï¼šè¿›è¡Œæ•°å­¦è®¡ç®—
tools = load_tools(["serpapi", "llm-math"], llm)

# AgentType.ZERO_SHOT_REACT_DESCRIPTIONï¼šç›´è¯‘å°±æ˜¯é›¶æ ·æœ¬_ååº”_æè¿°ï¼Œä»…é€šè¿‡æè¿°æ¥ç¡®å®šä½¿ç”¨å“ªä¸ªå·¥å…·
# verbose=Trueï¼š æ˜¾ç¤ºè¯¦ç»†æè¿°ï¼ˆå¯ä»¥ç†è§£ä¸ºAIçš„å¿ƒè·¯å†ç¨‹ï¼‰
agent = initialize_agent(tools, llm, AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)

print(agent.run("åŒ—äº¬æ˜¨å¤©æœ€é«˜æ°”æ¸©æ˜¯å¤šå°‘æ‘„æ°åº¦ï¼Ÿç„¶åç®—ä¸€ä¸‹è¿™ä¸ªæ•°å­—çš„å¹³æ–¹æ ¹"))
```
è¾“å‡ºï¼š
```bash
> Entering new  chain...
 I need to find the temperature first, then calculate the square root
Action: Search
Action Input: "Beijing yesterday highest temperature"
Observation: Beijing Temperature Yesterday. Maximum temperature yesterday: 102 Â°F (at 5:00 pm) Minimum temperature yesterday: 72 Â°F (at 5:00 am) Average temperature ...
Thought: I need to convert the temperature to Celsius
Action: Calculator
Action Input: 102 Fahrenheit to Celsius
Observation: Answer: 38.888888888888886
Thought: I now need to calculate the square root
Action: Calculator
Action Input: 38.888888888888886^(1/2)
Observation: Answer: 6.236095644623235
Thought: I now know the final answer
Final Answer: The highest temperature in Beijing yesterday was 38.888888888888886Â°C and the square root of this number is 6.236095644623235.

> Finished chain.
The highest temperature in Beijing yesterday was 38.888888888888886Â°C and the square root of this number is 6.236095644623235.
```

åŠŸèƒ½å¾ˆå¼ºå¤§ï¼Œä½†å®é™…ä½“éªŒä¸‹æ¥ä¸æ˜¯ç‰¹åˆ«ç¾å¥½ï¼Œä¸€æ˜¯ä¸ç¨³å®šï¼Œç»å¸¸éœ€è¦æŸ¥è¯¢å¾ˆå¤šæ¬¡æ‰èƒ½å¾—åˆ°ç»“æœï¼ŒäºŒæ˜¯æè¿°ç¨å¾®æ¨¡ç³Šæˆ–è€…å¤æ‚ä¸€ç‚¹ï¼Œå¾—åˆ°çš„ç»“æœå¯èƒ½å°±æ˜¯é”™è¯¯çš„ï¼Œæˆ–è€…æ²¡æ³•å¸¦å…¥åˆ°ä¸‹ä¸€æ­¥ï¼Œç›´æ¥æŠ¥é”™ ~~æ‘†çƒ‚~~ã€‚
serpapiæ³¨å†Œç”¨æˆ·æ¯æœˆæœ‰100æ¬¡å…è´¹çš„è°·æ­Œè°ƒç”¨ï¼Œç»ä¸èµ·æŠ˜è…¾ï¼Œä¸è¿‡æˆ‘ä»¬å¯ä»¥æ¥å°è¯•ä¸‹å…è´¹çš„duckduckgo search ~~(é¸­é¸­ç‹—ï¼‰~~)
- å®‰è£…`pip install duckduckgo-search`

```python
from langchain.llms import OpenAI
from langchain.agents import initialize_agent, AgentType, load_tools

llm = OpenAI(temperature=0, client="agent", model="text-davinci-003")
tools = load_tools(["ddg-search", "llm-math"], llm)
agent = initialize_agent(tools, llm, AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)
print(agent.run("åŒ—äº¬æ˜¨å¤©æœ€é«˜æ°”æ¸©æ˜¯å¤šå°‘æ‘„æ°åº¦ï¼Ÿç„¶åç®—ä¸€ä¸‹è¿™ä¸ªæ•°å­—çš„å¹³æ–¹æ ¹"))
```
è¾“å‡ºï¼š
```bash
> Entering new  chain...
 I need to find the highest temperature in Beijing yesterday and then calculate the square root of that number
Action: duckduckgo_search
Action Input: "Beijing highest temperature yesterday"
Observation: By Reuters BEIJING, June 22 â€” The temperature in Beijing breached 106 degrees Fahrenheit on Thursday and shattered the record for the hottest day in June as heatwaves that had seared nort
hern... On Friday, Beijing baked in temperatures as high as 40.3C, after sizzling at 41.1C on Thursday, the second-hottest day recorded by the Chinese capital in modern times. Beijing's all-time high of ... The city experienced its all-time recorded high of 41.9 C (107 F) on July 24, 1999. Chinese meteorologists say the current heat wave was caused by warm air masses associated with high-pressure ridges in the atmosphere, 
compounded by thin cloud covers and long daylight hours around the summer solstice. Last week, Beijing recorded its highest temperature for mid-June, with weather officials warning the public to stay indoors as the mercury hit 39.4C. With Agence France-Presse and Reuters... Beijing recorded a high temperature of 41.1 C yesterday (Jun 23) as the capital city continues to experience an ongoing heatwave, according to a report from Beijing News (æ–°äº¬æŠ¥). This isn't the first time the city has seen the heat cranked up to over 41 C, but the first time it's happened in June.
Thought: I now have the highest temperature in Beijing yesterday
Action: Calculator
Action Input: 41.1
Observation: Answer: 41.1
Thought: I now know the final answer
Final Answer: The highest temperature in Beijing yesterday was 41.1Â°C and its square root is 6.4.
```

ä¸€æ¬¡æŸ¥è¯¢ä¾¿å¾—åˆ°äº†ç»“æœï¼Œæ•ˆæœä¼¼ä¹æ›´å¥½ï¼Œä¸è¿‡æ—¥æœŸé”™äº†ï¼Œå¹¶ä¸æ˜¯æ˜¨å¤©ğŸ˜­

ä¹Ÿå¯ä»¥è°ƒç”¨æœ¬åœ°shell:
```python
from langchain.llms import OpenAI
from langchain.agents import initialize_agent, AgentType, load_tools

llm = OpenAI(temperature=0, client="shell", model="text-davinci-003")

tools = load_tools(["terminal", "llm-math"], llm)
self_ask_with_search = initialize_agent(
    tools, llm, agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION, verbose=True
)
self_ask_with_search.run("get the memory info by GB")
```

### 2.7 Memory
ç»´æŠ¤ç¨‹åºçŠ¶æ€ï¼Œæ‹¥æœ‰ä¸Šä¸‹æ–‡è®°å¿†
```python
from langchain.prompts import (ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate, MessagesPlaceholder)
from langchain.chains import ConversationChain
from langchain.chat_models import ChatOpenAI
from langchain.memory import ConversationBufferMemory

prompt = ChatPromptTemplate.from_messages([
    SystemMessagePromptTemplate.from_template(
        "ä»¥ä¸‹æ˜¯AIåŠ©æ‰‹ä¸äººç±»ä¹‹é—´çš„å‹å¥½å¯¹è¯ã€‚"
    ),
    MessagesPlaceholder(variable_name="history"),
    HumanMessagePromptTemplate.from_template("{input}")
])

llm = ChatOpenAI(temperature=0, client="memory")
memory = ConversationBufferMemory(return_messages=True)
conversation = ConversationChain(memory=memory, prompt=prompt, llm=llm)

while True:
    user = input("ç”¨æˆ·: ")
    answer = conversation.predict(input = user)
    print("AIåŠ©æ‰‹ï¼š", answer)
```
æˆ‘ä»¬ä¸AIè¿›è¡Œäº¤äº’ï¼š
```bash
ç”¨æˆ·: ä½ å¥½
AIåŠ©æ‰‹ï¼š ä½ å¥½ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ
```
æ¥ä¸‹æ¥éªŒè¯ç¡®å®å­˜åœ¨è®°å¿†ï¼š
```bash
ç”¨æˆ·: æˆ‘è¯´çš„æ˜¯ä¸Šä¸€å¥è¯æ˜¯ä»€ä¹ˆ
AIåŠ©æ‰‹ï¼š ä½ è¯´çš„ä¸Šä¸€å¥è¯æ˜¯"ä½ å¥½"ã€‚
```

## 3. æœ€å
LangChainçš„å¤§ä½“åŠŸèƒ½å¦‚ä¸Šï¼Œä¸LLMsä¸€æ ·ï¼Œç›®å‰ä¹Ÿåœ¨è“¬å‹ƒå‘å±•é˜¶æ®µï¼Œç”±äºå¤§è¯­è¨€æ¨¡å‹çš„ä¸ç¨³å®šæ€§ï¼Œç°åœ¨ä½¿ç”¨èµ·æ¥è¿˜æœ‰å¾ˆå¤šä¸å°½å¦‚äººæ„çš„åœ°æ–¹ï¼Œä½†æ˜¯æˆ‘ä»¬ä¹Ÿå¯ä»¥çœ‹åˆ°å…¶æ½œåŠ›å’Œæ„¿æ™¯ã€‚ä¸ªäººè§‰å¾—ï¼Œagentséƒ¨åˆ†æ˜¯æœ€å¸å¼•äººçš„åœ°æ–¹ï¼Œå°†LLMsçš„èƒ½åŠ›ç”±æ–‡æœ¬å»¶ä¼¸åˆ°ç¨‹åºä¹‹å¤–ï¼Œæå¤§åœ°æå‡äº†æƒ³è±¡ç©ºé—´ã€‚
æ›´å¤šå†…å®¹å¯ä»¥æŸ¥çœ‹[å®˜æ–¹æ–‡æ¡£](https://python.langchain.com/)ã€‚

## é™„ï¼šå‚è€ƒé“¾æ¥&æ–‡æ¡£

1. [å®˜æ–¹æ–‡æ¡£](https://python.langchain.com/)